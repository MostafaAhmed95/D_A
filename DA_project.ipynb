{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DA_project",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MostafaAhmed95/D_A/blob/master/DA_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxnLbblF1Tu8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch. utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRqr-56v184c",
        "colab_type": "code",
        "outputId": "01332b25-0648-4c11-c66d-85e1bea061b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "batch_size = 32\n",
        "test_batch_size = 100\n",
        "torch.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "# Transformations\n",
        "data_transformations = transforms.Compose([\n",
        "                           transforms.Grayscale(num_output_channels=1),\n",
        "                           transforms.Scale((28,28)),\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.1307,), (0.3081,))\n",
        "                       ])\n",
        "\n",
        "# Data Source\n",
        "svhn = datasets.SVHN('../data', download=True, transform=data_transformations)\n",
        "svhn_test = datasets.SVHN('../data', split='test', download=True, transform=data_transformations)\n",
        "mnist_test = datasets.MNIST('../data', train=False,transform=data_transformations, download=True)\n",
        "\n",
        "\n",
        "# Data loaders\n",
        "train_loader = DataLoader(svhn,\n",
        "                          batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(svhn_test,\n",
        "                         batch_size=test_batch_size, shuffle=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:211: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  \"please use transforms.Resize instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: ../data/train_32x32.mat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://ufldl.stanford.edu/housenumbers/test_32x32.mat to ../data/test_32x32.mat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64282624it [00:05, 12817964.90it/s]                              \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KY-qNjVpMNC9",
        "colab_type": "code",
        "outputId": "cc4f5068-41e8-48f8-e68d-e67b2fb6554a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "batch,labels = next(iter(train_loader))\n",
        "image = batch[0]\n",
        "np_image = image.data.numpy()\n",
        "print(np_image.shape)\n",
        "plt.imshow(np_image[0],cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqvUmdQVTN3K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):#This defines the structure of the NN.def __init__(self):super(Net, self).__init__()\n",
        "        # These are all operations that we are defining.# Unlike keras, this is not the network definition.# This is just initialization of the variables that # we are going to use in the `forward()` function.self.conv1 = nn.Conv2d(1, 10, kernel_size=5)self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        \n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5) \n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5) \n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "#         print(\"1\", x.shape)\n",
        "        #28x28x1\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))#12x12x10\n",
        "#         print(\"2\", x.shape)\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))#4x4x20\n",
        "#         print(\"3\", x.shape)\n",
        "        x = x.view(-1, 320)\n",
        "#         print(\"4\", x.shape)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x)\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model_cnn = Net().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25XCh4XPXLzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train our model\n",
        "def train( model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                       100. * batch_idx / len(train_loader), loss.item()))\n",
        "            \n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDEL7vzcY-0P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test( model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMYb8FmoabTi",
        "colab_type": "code",
        "outputId": "3845723c-2f0f-48d8-9564-39ee6ab40116",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epochs = 10\n",
        "lr = 0.01\n",
        "momentum = 0.5\n",
        "log_interval = 700\n",
        "\n",
        "model = model_cnn\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)\n",
        "\n",
        "\n",
        "    torch.save(model.state_dict(), \"sv_inno.pt\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/73257 (0%)]\tLoss: 2.338785\n",
            "Train Epoch: 1 [22400/73257 (31%)]\tLoss: 2.161071\n",
            "Train Epoch: 1 [44800/73257 (61%)]\tLoss: 2.246932\n",
            "Train Epoch: 1 [67200/73257 (92%)]\tLoss: 1.942676\n",
            "\n",
            "Test set: Average loss: 1.5680, Accuracy: 13850/26032 (53.20%)\n",
            "\n",
            "Train Epoch: 2 [0/73257 (0%)]\tLoss: 1.920066\n",
            "Train Epoch: 2 [22400/73257 (31%)]\tLoss: 1.271995\n",
            "Train Epoch: 2 [44800/73257 (61%)]\tLoss: 1.535981\n",
            "Train Epoch: 2 [67200/73257 (92%)]\tLoss: 0.914516\n",
            "\n",
            "Test set: Average loss: 0.8441, Accuracy: 20098/26032 (77.20%)\n",
            "\n",
            "Train Epoch: 3 [0/73257 (0%)]\tLoss: 1.499970\n",
            "Train Epoch: 3 [22400/73257 (31%)]\tLoss: 1.015271\n",
            "Train Epoch: 3 [44800/73257 (61%)]\tLoss: 0.750436\n",
            "Train Epoch: 3 [67200/73257 (92%)]\tLoss: 1.222007\n",
            "\n",
            "Test set: Average loss: 0.7350, Accuracy: 20863/26032 (80.14%)\n",
            "\n",
            "Train Epoch: 4 [0/73257 (0%)]\tLoss: 0.678391\n",
            "Train Epoch: 4 [22400/73257 (31%)]\tLoss: 1.117928\n",
            "Train Epoch: 4 [44800/73257 (61%)]\tLoss: 0.572010\n",
            "Train Epoch: 4 [67200/73257 (92%)]\tLoss: 1.001003\n",
            "\n",
            "Test set: Average loss: 0.6583, Accuracy: 21106/26032 (81.08%)\n",
            "\n",
            "Train Epoch: 5 [0/73257 (0%)]\tLoss: 0.888474\n",
            "Train Epoch: 5 [22400/73257 (31%)]\tLoss: 1.441026\n",
            "Train Epoch: 5 [44800/73257 (61%)]\tLoss: 1.366565\n",
            "Train Epoch: 5 [67200/73257 (92%)]\tLoss: 1.048230\n",
            "\n",
            "Test set: Average loss: 0.6596, Accuracy: 21017/26032 (80.74%)\n",
            "\n",
            "Train Epoch: 6 [0/73257 (0%)]\tLoss: 0.720828\n",
            "Train Epoch: 6 [22400/73257 (31%)]\tLoss: 0.596468\n",
            "Train Epoch: 6 [44800/73257 (61%)]\tLoss: 0.737068\n",
            "Train Epoch: 6 [67200/73257 (92%)]\tLoss: 1.369749\n",
            "\n",
            "Test set: Average loss: 0.6331, Accuracy: 21276/26032 (81.73%)\n",
            "\n",
            "Train Epoch: 7 [0/73257 (0%)]\tLoss: 0.853000\n",
            "Train Epoch: 7 [22400/73257 (31%)]\tLoss: 0.840043\n",
            "Train Epoch: 7 [44800/73257 (61%)]\tLoss: 1.067279\n",
            "Train Epoch: 7 [67200/73257 (92%)]\tLoss: 0.744797\n",
            "\n",
            "Test set: Average loss: 0.6521, Accuracy: 21156/26032 (81.27%)\n",
            "\n",
            "Train Epoch: 8 [0/73257 (0%)]\tLoss: 1.079593\n",
            "Train Epoch: 8 [22400/73257 (31%)]\tLoss: 0.593148\n",
            "Train Epoch: 8 [44800/73257 (61%)]\tLoss: 0.703786\n",
            "Train Epoch: 8 [67200/73257 (92%)]\tLoss: 0.932255\n",
            "\n",
            "Test set: Average loss: 0.5867, Accuracy: 21632/26032 (83.10%)\n",
            "\n",
            "Train Epoch: 9 [0/73257 (0%)]\tLoss: 0.577959\n",
            "Train Epoch: 9 [22400/73257 (31%)]\tLoss: 1.195690\n",
            "Train Epoch: 9 [44800/73257 (61%)]\tLoss: 1.596556\n",
            "Train Epoch: 9 [67200/73257 (92%)]\tLoss: 0.889547\n",
            "\n",
            "Test set: Average loss: 0.5922, Accuracy: 21476/26032 (82.50%)\n",
            "\n",
            "Train Epoch: 10 [0/73257 (0%)]\tLoss: 0.923253\n",
            "Train Epoch: 10 [22400/73257 (31%)]\tLoss: 0.879222\n",
            "Train Epoch: 10 [44800/73257 (61%)]\tLoss: 0.626817\n",
            "Train Epoch: 10 [67200/73257 (92%)]\tLoss: 0.845324\n",
            "\n",
            "Test set: Average loss: 0.5895, Accuracy: 21605/26032 (82.99%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}